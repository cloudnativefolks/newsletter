---
layout: post
title: "KubeCon2024 Edition: CloudNativeFolks Community"
categories: Newsletter 
--- 

### KubeCon24 PARIS, FRANCE

<iframe width="720" height="720" src="https://www.youtube.com/embed/1u5LtsJqyrA?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Project Carvel: Composable Tools for Application Management" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 1.Project Carvel: Composable Tools for Application Management

Project Carvel provides a suite of reliable, single-purpose, and composable tools designed for application management. This comprehensive overview highlights the functionalities and use cases of various tools within the Project Carvel ecosystem, demonstrating their practical applications through examples.

- **Composability and Reliability**: The core philosophy behind Project Carvel is to offer a set of tools that are both composable and reliable. Each tool is designed to perform a specific task, ensuring simplicity and effectiveness in managing applications.

- **Tools Overview**:
    - **ytt (YAML Templating Tool)**: ytt is a powerful tool for templating YAML configurations. It understands YAML as a data structure, enabling users to manipulate YAML in unique ways. ytt is versatile, supporting not just Kubernetes resources but also any YAML-based configurations like GitHub actions.
    - **kapp**: kapp is used for deploying and managing resources on Kubernetes clusters. It treats resources as a group and understands the dependencies between them, ensuring that resources are applied in a sensible order and reflecting the desired state accurately.
    - **kbld (Kubernetes Build)**: kbld focuses on managing image references in configuration files. It resolves image tags to immutable digests, ensuring that the exact images used during development are the ones deployed to production.
    - **imgpkg**: imgpkg is designed for bundling, distributing, and versioning configurations using OCI images. It allows for the creation of versioned bundles that can be relocated across registries, supporting air-gapped environments and ensuring integrity through immutability.
    - **Carvel Packaging APIs**: These APIs facilitate the distribution and installation of software across Kubernetes clusters. They provide a higher-level abstraction over the lower-level tools, enabling easier management and deployment of applications.

- **Practical Demonstration**: The presenters showcased practical uses of each tool, starting with ytt to template and manipulate YAML configurations, then moving to kapp for deployment management. They demonstrated how kbld secures image references and how imgpkg bundles configurations for distribution. Finally, they discussed the Carvel Packaging APIs, which streamline the deployment process across different environments.

<iframe width="720" height="720" src="https://www.youtube.com/embed/3OSQdiKTNU8?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="When They Go High, We Go Low – Hooking Libc Calls to Debug Kubernetes Apps - Tal Zwick, MetalBear" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 2.When They Go High, We Go Low – Hooking Libc Calls to Debug Kubernetes Apps - Tal Zwick, MetalBear

This talk, presented by Tal Zwick from MetalBear, delves into innovative low-level techniques used to enhance the development experience of cloud-native applications through a tool named Mird, developed in Rust. The primary focus is on addressing the challenges cloud-native developers face, emphasizing the significance of running and debugging code in environments closely resembling production settings.

### **Key Points:**

- **Objective**: The main challenge tackled is improving the cloud-native developer experience, particularly the ease of running and debugging code. Mird offers a unique solution by enabling developers to execute applications locally while still interacting with cluster resources, bridging the gap between local development and cloud-native environments.

- **Mird Overview**: Mird facilitates the local execution of cloud-native applications with seamless cluster integration. This approach allows developers to maintain productive development practices without compromising the complexity inherent in cloud-native applications. It essentially merges the simplicity of local development with the robustness of cloud-native operations.

- **Technical Insights**: A considerable portion of the talk is dedicated to the technical underpinnings of Mird. Key techniques include:
    - Hooking libc functions using the dynamic instrumentation toolkit, Frida, to intercept and manipulate system calls, directing them towards cluster resources when necessary.
    - Employing dynamic libraries for process-level virtualization, creating a transparent connection between the local development environment and cluster resources.
    - Utilizing environment variables and configuration flags to determine the execution context (local vs. cluster) for specific operations.

- **Development Workflow**: Mird enhances the development workflow by allowing for real-time debugging and interaction with live data and services within the cluster. This setup supports a more intuitive and efficient debugging process, facilitating immediate feedback and iteration.

<iframe width="720" height="720" src="https://www.youtube.com/embed/9EARwoRStBY?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Keynote: Cloud Native in its Next Decade - Davanum Srinivas &amp; Lin Sun" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 3.Keynote: Cloud Native in its Next Decade - Davanum Srinivas &amp; Lin Sun

The keynote speech, presented by Davanum Srinivas and Lin Sun, delves into the progression and future direction of cloud-native technologies over the next decade. Their presentation covers a comprehensive overview of the Cloud Native Computing Foundation's (CNCF) achievements, project incubations, and the evolving landscape of cloud-native technologies. Here are the key insights from their discussion:

- **Community and Governance:** The CNCF's Technical Oversight Committee (TOC) plays a crucial role in guiding the foundation's technical direction. With new members added, the committee ensures diverse representation and governance across cloud-native projects.

- **Project Evolution:** Highlighting the growth from incubation to graduation, the presentation underscores the importance of a clear pathway for project development within the CNCF ecosystem. This process promotes stability, maturity, and innovation among cloud-native projects.

- **Historical Reflections:** A look back at the architecture and key milestones since 2015 reveals the rapid evolution of cloud-native technologies. From the inception of Kubernetes and Prometheus to the introduction of newer projects like K3s and WASM, the landscape has continuously expanded and diversified.

- **Future Directions:** The keynote speculates on the next decade of cloud-native technology, emphasizing areas like AI, sustainability, security, edge computing, and service mesh. It suggests that these technologies will remain at the forefront of cloud-native innovation.

- **Big Disruptions:** Predictions about the next big disruptions in cloud-native include the integration of Cloud Native and AI, simplicity in technology, and the need for consolidation amidst the proliferation of projects. Additionally, the emphasis on developer-friendly APIs and sustainable, efficient infrastructure is expected to shape the future.

- **Community Engagement:** The speech encourages community engagement and participation in shaping the future of cloud-native technologies. It concludes with an invitation to join a panel discussion with TOC members to further explore these themes.

Insights based on numbers:
- **184 Projects:** The CNCF has grown to encompass 184 projects, indicating the vast scale and diversity of the cloud-native ecosystem.
- **Decade of Growth:** Reflecting on the past decade, the presentation provides a roadmap for the next, highlighting the key areas of technological advancement and community focus.

<iframe width="720" height="720" src="https://www.youtube.com/embed/D0jE4BSzX3Y?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Prometheus Update from the Maintainers - Bryan Boreham, Grafana Labs &amp; Simon Pasquier, Red Hat" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 4.Prometheus Update from the Maintainers - Bryan Boreham, Grafana Labs &amp; Simon Pasquier, Red Hat

The presentation by Bryan Boreham and Simon Pasquier provides an in-depth update on Prometheus, covering its evolution, recent enhancements, and future directions. As an integral part of the cloud-native monitoring landscape, Prometheus has continued to grow and adapt to meet the needs of its users. Below are the key insights and updates shared by the maintainers:

- **Community Growth:** Prometheus has seen substantial growth in its community and contributions, reflecting its widespread adoption and the active involvement of its user base.

- **Recent Developments:**
  - **Releases and Support:** Over the past year, Prometheus made significant progress with eight releases, including the introduction of Long-Term Support (LTS) versions for users seeking stability.
  - **Client and Exporter Updates:** The Java client reached 1.0, marking a major milestone with a comprehensive rearchitecture. The Go client and various exporters saw numerous releases, indicating ongoing enhancements.

- **Feature Enhancements:**
  - **Native Histograms:** A major focus has been on improving histogram resolution and efficiency. While still experimental, native histograms promise more detailed and accurate data representation.
  - **OpenTelemetry Integration:** An experimental ingestion endpoint for OpenTelemetry metrics has been introduced, signaling closer integration with the broader observability ecosystem.

- **Performance Improvements:** Efforts to reduce Prometheus's memory footprint and improve efficiency have been successful, with further optimizations ongoing, such as duplicate label reduction.

- **Future Roadmap:**
  - **Version 3.0:** Plans for Prometheus 3.0 include solidifying experimental features into the core offering and simplifying the upgrade process for users. The transition from version 2 to 3 aims to be seamless, building on the project's commitment to not breaking user workflows.
  - **Enhanced OpenTelemetry Support:** Enhanced support for OpenTelemetry metrics, including compatibility with UTF-8 metric and label names, aims to simplify integration and use.
  - **UI Improvements:** A refreshed user interface is in development, focusing on a cleaner and more efficient design without drastically altering the user experience.

- **Community and Contribution:** The maintainers emphasized the importance of community contributions and engagement. They highlighted opportunities for new contributors to get involved, including a dedicated session for contributors at the conference.

Insights based on numbers:
- **12 Years of Development:** Reflecting on its long history, Prometheus has matured significantly, joining the CNCF in 2016 and reaching graduation two years later.
- **Growth in Installations:** The presentation showcased a steady increase in Prometheus installations, indicating its widespread acceptance and use across various industries.

<iframe width="720" height="720" src="https://www.youtube.com/embed/JFLNFJT59DY?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="GitOps Continuous Delivery at Scale with Flux - Stefan Prodan" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


### 5.GitOps Continuous Delivery at Scale with Flux - Stefan Prodan

Stefan Prodan's talk on "GitOps Continuous Delivery at Scale with Flux" provides an insightful overview of the Flux project, its roadmap, and strategies for scaling GitOps practices. Flux, as a foundation layer for continuous delivery platforms, is designed to extend Kubernetes in numerous ways, offering flexibility and scalability in managing deployments. Key insights from the talk include:

- **Flux Definition and Capabilities:**
  - Flux is not just a platform but a Kubernetes extension that includes 13 Custom Resource Definitions (CRDs) and six controllers, emphasizing its extensibility and adaptability to various use cases and environments.

- **Scaling Strategies:**
  - Prodan outlines a journey for scaling Flux, starting with source optimization and control fine-tuning, moving to vertical scaling, and ultimately considering horizontal scaling through sharding for larger deployments.

- **Roadmap Highlights:**
  - The roadmap for Flux includes reaching general availability for 80% of its APIs, integrating notary and CD events for improved security and interoperability, and enhancements to Helm OCI support.

- **Sustainability and Community Involvement:**
  - The sustainability of Flux is seen as a collaborative effort within the community. Prodan encourages contributions and a new model for maintainership focused on specific features to foster a broader base of maintainers and specialists.

Insights based on numbers:
- **Benchmarks and Performance:**
  - Prodan shares benchmarking results showing Flux's capability to handle 1K Helm releases in about 8 minutes and 1K customizations in around 4 minutes, highlighting its efficiency in managing large-scale deployments.
<iframe width="720" height="720" src="https://www.youtube.com/embed/KaXIq8Qv77A?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Shift-Left: Past, Present, and Future of Validation in CI... Alexander Zielenski &amp; Stefan Schimanski" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 6.Shift-Left: Past, Present, and Future of Validation in CI

The presentation by Alexander Zielenski and Stefan Schimanski on "Shift-Left: Past, Present, and Future of Validation in CI" explores the evolution of validation mechanisms in Kubernetes and the continuous effort to improve developer experience by integrating validation more deeply into the development process. Here are the key insights from their discussion:

- **Evolution of Validation:** 
  - The talk begins with a historical overview, highlighting how validation has been a core aspect of Kubernetes since its inception. Initially, validation was primarily server-side, relying on the Kubernetes API server to catch errors.

- **Shift-Left Concept:**
  - The "shift-left" concept refers to moving validation closer to the development phase, ideally providing immediate feedback to developers. This approach aims to identify and rectify errors early in the CI/CD pipeline, enhancing efficiency and reducing the iteration time.

- **Challenges with Current Validation Methods:**
  - The presenters discuss the limitations of existing validation methods, including client-side validation with `kubectl` and server-side dry run validations. These methods either lack comprehensive error reporting or require access to a Kubernetes cluster, which can be impractical in CI environments.

- **Introduction of CEL (Common Expression Language):**
  - To address these limitations, Kubernetes has introduced support for the Common Expression Language (CEL) in Custom Resource Definitions (CRDs). CEL allows for more complex and expressive validations, including field immutability and conditional logic.

- **Automated Validation Ratcheting:**
  - Another significant development is automated validation ratcheting, which allows CRDs to be updated with stricter validation rules without breaking existing resources. This feature facilitates the gradual strengthening of validation rules over time.

- **Future Directions:**
  - The future of validation in Kubernetes focuses on further enhancing the expressiveness and applicability of CRD validations. Efforts are underway to encode native Kubernetes type validations using CEL, aiming to provide consistent and comprehensive validation across all resource types.

- **Tooling for Enhanced Validation:**
  - The presentation introduces `kubectl validate`, a new tool designed to leverage these advancements in validation technology. `kubectl validate` aims to provide instant feedback on validation errors, using the same validation logic as the Kubernetes API server but executed client-side.

Insights based on numbers:
- **Performance and Efficiency:** The introduction of CEL and automated validation ratcheting represents a significant leap in the performance and efficiency of Kubernetes validation mechanisms, enabling more complex validations without compromising on feedback speed or accuracy.

<iframe width="720" height="720" src="https://www.youtube.com/embed/TOX8UCnKHWo?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Composable Systems in Kubernetes - Michele Gazzetti, IBM Research Europe - Ireland" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 7.Composable Systems in Kubernetes - Michele Gazzetti, IBM Research Europe - Ireland

Michele Gazzetti's presentation on "Composable Systems in Kubernetes" explores the integration and management of composable disaggregated infrastructure (CDI) within Kubernetes environments. Gazzetti discusses the challenges and developments in creating more flexible and efficient systems by dynamically allocating and managing resources such as compute, memory, accelerators, and storage. Here are the key insights from his discussion:

- **CDI Overview:**
  - CDI refers to a set of disaggregated physical resources that can be dynamically allocated and managed via a fabric. This approach allows for more efficient use of resources by adjusting allocations based on current needs.

- **Challenges of CDI Integration:**
  - Integrating CDI into Kubernetes introduces complexity in managing resources at a granular level. The primary challenge is to abstract the complexity of CDI management from the end-users and provide a seamless interface within Kubernetes for resource allocation.

- **Sunfish Framework:**
  - Sunfish, an open framework under the OpenFabrics Alliance, aims to address these challenges by abstracting vendor-specific APIs and providing a unified view of available resources. It manages the dynamic selection and reconfiguration of resources based on user-defined policies.

- **Composable Resource Operator:**
  - The Composable Resource Operator is a proof-of-concept developed to integrate CDI within Kubernetes. It allows users to request composable resources, like GPUs, through Kubernetes Custom Resource Definitions (CRDs). The operator manages the attachment and detachment of these resources to nodes.

- **Demo and Implementation:**
  - A demonstration showcases the dynamic allocation of GPUs to a Kubernetes node based on a pod's requirements. The process involves creating a "composability request" through a CRD, which triggers the allocation of resources from the pool to the specified node.

- **Management Complexity:**
  - Successfully integrating CDI requires managing the lower levels of the stack and ensuring compatibility with various CDI solutions from different vendors. This includes handling the attachment and detachment processes and ensuring that resources are recognized and utilized effectively by Kubernetes.

- **Future Directions:**
  - Future work will focus on enhancing compatibility with the Sunfish framework, exploring various CDI solutions, and investigating the sustainability impact of CDI in data centers. Other areas of interest include addressing scheduling topology constraints and finding ways to merge the views of Kubernetes scheduling with physical infrastructure constraints.

Insights based on numbers:
- **Resource Efficiency and Dynamic Allocation:**
  - CDI's dynamic allocation mechanism offers a more efficient utilization of data center resources by reducing over-provisioning and enabling the precise allocation of high-value resources like GPUs.
 
<iframe width="720" height="720" src="https://www.youtube.com/embed/ZcgFgb8dLOw?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Distributed AI: Using NATS.Io to Seamlessly Connect AI Applications... Tomasz Pietrek &amp; Jeremy Saenz" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 8.Composable Systems in Kubernetes - Michele Gazzetti, IBM Research Europe - Ireland

Tomasz Pietrek and Jeremy Saenz's presentation introduces the utilization of NATS.io for connecting AI applications, emphasizing its application in distributed AI systems. NATS.io, a high-performance messaging system, is showcased as a pivotal technology for AI at the edge, offering a simplified, efficient, and scalable solution for AI workloads. The presentation covers key features, recent updates to NATS, and a practical demonstration of AI model inference using NATS for messaging. Here are the detailed insights:

- **NATS Overview:**
  - **Core Functions:** NATS provides basic messaging patterns like publish/subscribe and request/reply, foundational for distributed system communication. Its capabilities extend to persistence through JetStream, facilitating at-least-once delivery semantics.
  - **Distributed System Design:** The emphasis on distributed system design highlights NATS's strengths in connecting various components seamlessly, including cloud, data center, and edge devices. NATS simplifies the architecture by offering unified messaging for data exchange, service discovery, and configuration management across disparate environments.

- **Enhancements and Use Cases:**
  - **Tracing and Monitoring:** The introduction of tracing in the upcoming NATS version promises enhanced visibility into message flows across multi-layered architectures, vital for debugging and performance optimization in AI workloads.
  - **Dynamic Resource Allocation:** Through its key-value stores and JetStream, NATS supports dynamic resource allocation, essential for managing AI model deployments and data streams in real-time.

- **AI at the Edge Demonstration:**
  - The live demonstration focused on AI model inference for object detection, showcasing NATS's role in facilitating efficient data transfer between edge devices and AI models. The use of NATS reduced latency and improved the responsiveness of AI applications, demonstrating its effectiveness in edge computing scenarios.

- **Operational Simplicity and Scalability:**
  - **Lightweight and Flexible:** NATS's operational simplicity, with its small binary size and comprehensive client support, underscores its adaptability to various deployment scenarios, from cloud-based services to edge devices.
  - **Leaf Nodes and Global Networks:** The discussion on leaf nodes and the global network architecture of NATS highlighted its scalability and flexibility, enabling seamless integration of local and remote systems for distributed AI applications.

- **Community and Future Directions:**
  - **Community Contributions:** The presentation encouraged community engagement, with an open invitation for contributions to NATS and related projects. The focus on community-driven development is poised to accelerate the evolution of NATS and its ecosystem.
  - **Sustainability and Innovation:** Looking forward, the speakers envisioned exploring NATS's potential to enhance data center sustainability through intelligent resource management and to address complex scheduling and connectivity challenges in distributed AI environments.

Insights based on numbers:
- **Performance Metrics:** Benchmarking demonstrations showcased NATS's high throughput capabilities, essential for the data-intensive requirements of AI workloads.

<iframe width="720" height="720" src="https://www.youtube.com/embed/euYhIn4leW0?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Observable Feature Rollouts with OpenTelemetry and OpenFeature - Daniel Dyla &amp; Michael Beemer" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 9.Observable Feature Rollouts with OpenTelemetry and OpenFeature - Daniel Dyla &amp; Michael Beemer

Daniel Dyla and Michael Beemer’s presentation focuses on leveraging OpenTelemetry and OpenFeature for observability in feature rollouts, offering insights into managing and monitoring feature flags in a distributed microservices architecture. Their talk outlines the integration of these tools to enhance deployment strategies and mitigate risks associated with new features. Here are the detailed insights:

- **OpenFeature Introduction:**
  - **Purpose:** OpenFeature is an open specification for vendor-agnostic, community-driven feature flags. It aims to standardize feature flag management across different environments and systems, supporting both commercial and open-source tools.
  - **Feature Flags:** Feature flags serve as pivot points in code that can be dynamically adjusted without deploying new code versions, facilitating decoupled release strategies and risk management.

- **Feature Flag Benefits and Challenges:**
  - **Benefits:** Feature flags enable decoupled deployments, risk reduction by controlling the impact radius, and experimental A/B testing with different feature variations.
  - **Challenges:** The primary challenge highlighted is the complexity added to the system, especially in a microservices architecture where multiple feature flags can alter code paths dynamically, necessitating enhanced monitoring.

- **OpenTelemetry for Monitoring:**
  - **Functionality:** OpenTelemetry provides a suite of APIs and SDKs for collecting telemetry data (events, traces, metrics) in a vendor-neutral manner, allowing for comprehensive observability across services.
  - **Data Collection:** The talk underscores the importance of selecting the appropriate telemetry signals based on the volume of data, structured vs. unstructured data, and the specific analysis needs.

- **Observable Feature Rollouts:**
  - The speakers present a hypothetical scenario involving a sneaker shop to illustrate the process of safely rolling out a new database read replica feature behind a feature flag.
  - **Process Steps:** The process includes adding the feature flag, monitoring its impact via OpenTelemetry, controlling the rollout to a subset of users, and analyzing the telemetry data to identify and resolve issues before a full rollout.

- **Practical Demonstration:**
  - **Integration:** A demonstration shows how OpenFeature and OpenTelemetry work together to monitor feature flag evaluations and their impact on system behavior, utilizing traces to analyze and troubleshoot issues.
  - **Rollback Mechanism:** The ability to quickly rollback a feature for specific users based on observed telemetry data highlights the dynamic control feature flags offer in production environments.

- **Conclusion and Best Practices:**
  - **Comprehensive Monitoring:** The combination of OpenFeature for feature flag management and OpenTelemetry for observability enables a robust strategy for feature rollouts, emphasizing the need for continuous monitoring and analysis.
  - **Future Observability:** The presentation concludes with a Q&A session, addressing inquiries about automated rollbacks, handling feature flag-related metrics to avoid cardinality issues, and the support for these practices in existing tools.

Insights based on numbers:
- **Performance Improvements:** The hypothetical scenario showcased how implementing a read replica could significantly reduce database response times, demonstrating the tangible benefits of observable feature rollouts.

<iframe width="720" height="720" src="https://www.youtube.com/embed/hENwFyrtm1g?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Open Policy Agent (OPA) Intro &amp; Deep Dive - Anders Eknert, Styra &amp; Xander Grzywinski, Microsoft" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 10. Open Policy Agent (OPA) Intro &amp; Deep Dive - Anders Eknert, Styra &amp; Xander Grzywinski, Microsoft

The presentation by Anders Eknert and Xander Grzywinski offers a comprehensive introduction to the Open Policy Agent (OPA) and a deep dive into its functionalities, benefits, and the ecosystem. The talk addresses the fundamentals of OPA, project updates, and its integration within the Kubernetes environment through the OPA Gatekeeper project. Here are the detailed insights:

- **OPA Fundamentals:**
  - **Definition and Purpose:** OPA is an open-source, general-purpose policy engine designed to unify policy enforcement across the cloud-native stack. It decouples policy from application logic, allowing policies to be managed and enforced independently.
  - **Policy as Code:** OPA emphasizes treating policy as code, supporting practices like code review, testing, and deployment automation for policy management. This approach facilitates collaboration and centralizes policy governance.
  - **Rego Policy Language:** Policies are expressed in Rego, a declarative language developed specifically for OPA, enabling fine-grained, context-aware policy definition.

- **Project Updates and Roadmap:**
  - **OPA 1.0 Release:** The upcoming release aims to address language ambiguities and introduce syntactical improvements for better readability and maintainability of Rego policies.
  - **Future Features:** The roadmap includes runtime schema validation, enhanced configuration options, improved testing output for OPA policies, and new language features to facilitate policy writing and debugging.

- **OPA Gatekeeper for Kubernetes:**
  - **Introduction:** OPA Gatekeeper extends OPA's capabilities to Kubernetes, offering a Kubernetes-native policy management solution. It leverages OPA for validating and mutating admission control, enforcing policies at the Kubernetes API level.
  - **Core Features:** Gatekeeper introduces constraint templates for policy definition, supports data mutation through custom resource definitions (CRDs), and provides auditing capabilities to ensure compliance with policies across Kubernetes resources.

- **Integration and Use Cases:**
  - **Admission Control:** Demonstrates how Gatekeeper can enforce policies on Kubernetes resources during the admission process, preventing non-compliant resources from being deployed.
  - **Mutation:** Gatekeeper can mutate Kubernetes objects based on specified policies, enabling automatic adjustments to resources, such as adding labels or annotations.
  - **Auditing:** Offers insights into existing resources' compliance, highlighting violations and facilitating governance across Kubernetes clusters.

- **Community and Ecosystem:**
  - **Vibrant Community:** OPA boasts a strong community of users and contributors, with extensive integrations across the cloud-native ecosystem, emphasizing the project's maturity and wide adoption.
  - **Tooling and Editor Support:** The ecosystem includes tools for writing, testing, and deploying Rego policies, with editor integrations available for a seamless development experience.

Insights based on numbers:
- **Adoption Metrics:** OPA's widespread adoption is underscored by its GitHub stars, Slack users, and download numbers, reflecting its importance in the cloud-native landscape.

<iframe width="720" height="720" src="https://www.youtube.com/embed/jaC9eVEcwzk?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="The Chain of Trust: Towards SLSA L3 with Tekton Trusted Artifacts - Jerop Kipruto &amp; Andrea Frittoli" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 11. The Chain of Trust: Towards SLSA L3 with Tekton Trusted Artifacts - Jerop Kipruto &amp; Andrea Frittoli

Andrea Frittoli's presentation delves into enhancing the chain of trust in the software development lifecycle (SDLC) with Tekton, focusing on achieving Supply-chain Levels for Software Artifacts (SLSA) Level 3 compliance. Tekton, a powerful cloud-native CI/CD framework, plays a crucial role in establishing a trusted environment for building, testing, and deploying software. Key insights from the talk include:

- **Chain of Trust in SDLC:** The chain of trust concept ensures reliability at each step of the SDLC, from code writing to deployment. A single breach in this chain can compromise the entire process, underscoring the need for stringent security measures.

- **SLSA Framework:** SLSA provides a security framework defining levels of trust for software artifacts. Frittoli highlighted the focus on SLSA Level 3 for builds, which requires a hardened, secure build platform and provenance for artifacts.

- **Tekton Overview:** Tekton extends Kubernetes to model CI/CD pipelines using custom resources, offering a scalable and secure way to automate software delivery. It supports security features like artifact signing and verifying to enhance trust.

- **Tekton Trusted Artifacts:** The concept of "Tekton Artifacts" was introduced to further secure the SDLC by ensuring the integrity of artifacts passed between steps in a Tekton pipeline. This initiative aims to meet SLSA Level 3 requirements by attesting to each step's inputs and outputs, providing a verifiable chain of custody for artifacts.

- **Demonstration:** Frittoli presented a demo highlighting potential security vulnerabilities when using shared workspaces without proper artifact attestation. The demonstration showed how Tekton Artifacts could mitigate these risks by ensuring each artifact's provenance is verified before it is consumed by subsequent steps.

- **Future Directions:** The presentation outlined upcoming features for Tekton, including step attestation, artifact definition in the Tekton API, and the integration of standards like SPIFFE, in-toto, and CD Events. These features aim to provide stronger guarantees about the security and provenance of software artifacts.

Insights based on numbers:
- **Community and Adoption:** Tekton's robust community and wide adoption among major companies underscore its importance as a tool for building secure, cloud-native CI/CD pipelines.

<iframe width="720" height="720" src="https://www.youtube.com/embed/lswkWQU4_W0?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Enabling Coordinated Checkpointing for Distributed HPC Applicati... Radostin Stoyanov &amp; Adrian Reber" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 12. Enabling Coordinated Checkpointing for Distributed HPC Applications - Radostin Stoyanov & Adrian Reber 

The presentation by Radostin Stoyanov and Adrian Reber introduces advancements in enabling coordinated checkpointing for distributed High-Performance Computing (HPC) applications, utilizing the Checkpoint/Restore in Userspace (CRIU) tool and Kubernetes. Their work focuses on overcoming the limitations of traditional checkpointing methods by facilitating a synchronized, distributed checkpointing mechanism that is critical for fault tolerance and efficient computation in HPC environments. Here are the detailed insights:

- **Checkpoint/Restore in Userspace (CRIU):** CRIU is a tool that enables the checkpointing and restoring of Linux processes in userspace. Originally designed for container migration, CRIU has been pivotal in enabling stateful snapshotting and restoration of applications, making it foundational for the discussed advancements.

- **Challenges in Distributed HPC Applications:**
  - Traditional checkpointing methods, while effective for single-node applications, fall short in distributed settings where coordinated state snapshotting across multiple nodes is required.
  - The need for a coordinated checkpointing mechanism arises from the complexity of HPC applications, which often span across numerous computational nodes, necessitating a synchronized state capture to ensure consistency and fault tolerance.

- **Coordinated Checkpointing Mechanism:**
  - The researchers have developed a coordination tool that interfaces with CRIU to enable synchronized checkpointing across distributed systems. This tool utilizes CRIU's action script hooks to pause and resume processes, ensuring a consistent global state is captured.
  - The coordination tool registers CRIU instances and manages dependencies between them, allowing for a coordinated checkpoint and restore process that aligns with the needs of distributed HPC applications.

- **Integration into Kubernetes:**
  - The present work aims to integrate these checkpointing capabilities into Kubernetes, leveraging the container orchestration platform to manage and automate checkpointing tasks.
  - Kubernetes' extensibility and wide adoption make it an ideal platform for deploying HPC applications that benefit from coordinated checkpointing, providing resilience and flexibility in managing computational workloads.

- **Demonstration and Use Cases:**
  - A demonstration showcased the migration of a containerized application across nodes, illustrating the potential of CRIU and the coordination tool in facilitating stateful container migrations.
  - Use cases for this technology extend beyond simple migrations, including fault tolerance in long-running computations, dynamic resource allocation, and load balancing in cloud environments.

- **Future Work and Challenges:**
  - The presentation outlines future directions, including the refinement of the coordination mechanism, deeper integration with Kubernetes' ecosystem, and enhancements to support a broader range of distributed computing patterns.
  - Addressing the challenges of capturing and restoring state in distributed systems, especially regarding network connections and external dependencies, remains an area of active research.

Insights based on numbers:
- **Advancement in CRIU and Kubernetes:** The work represents significant progress in the integration of CRIU within Kubernetes, offering a path toward robust, coordinated checkpointing in distributed systems.

<iframe width="720" height="720" src="https://www.youtube.com/embed/mDPLioNIIjo?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="CRI-O Odyssey: Exploring New Frontiers in Container Runtimes - Julien Ropé &amp; Sohan Kunkerkar" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 13.CRI-O Odyssey: Exploring New Frontiers in Container Runtimes - Julien Ropé &amp; Sohan Kunkerkar

The presentation by Julien Ropé and Sohan Kunkerkar focuses on the latest advancements and future directions in CRI-O, a lightweight container runtime for Kubernetes. The speakers delve into several key areas, including the project's community growth, technical enhancements, and innovative features aimed at addressing the evolving needs of containerized applications. Here are the detailed insights:

- **Community Growth and CNCF Graduation:**
  - The project has witnessed steady growth in contributions and interest, as evidenced by the increasing number of GitHub stars. This growth underscores the community's robust engagement and the project's maturation.

- **Upcoming Features in Release 1.30:**
  - Enhancements include easier deployment of Seccomp profiles, support for s390 architecture, and the introduction of a split image filesystem. These improvements aim to enhance security, compatibility, and resource efficiency.

- **Confidential Containers:**
  - A significant focus is on integrating confidential containers into CRI-O, which ensures workload confidentiality by encrypting memory in use. This approach leverages virtual machines running on hypervisors with hardware support for memory encryption, enhancing the security of sensitive workloads.

- **Wasm Integration:**
  - The integration of WebAssembly (Wasm) with CRI-O and Kubernetes opens new possibilities for deploying lightweight, secure, and portable applications across a variety of architectures and environments, including edge computing scenarios.

- **Rootless Containers and Enhanced Security:**
  - CRI-O is advancing in supporting rootless containers, which run without root privileges, enhancing security and minimizing the risk of privilege escalation attacks. This effort includes developments in proc mount options and username space pods, further securing containerized applications.

- **Split Image Filesystem and Space Efficiency:**
  - The introduction of a split image filesystem in CRI-O addresses disk space concerns by separating read-only image layers from writable layers. This feature not only optimizes space usage but also improves the isolation of containers.

- **Future Directions:**
  - Future work includes automatic reloading of mirror config for registry, implementation of a Rust-based NRI framework, direct loading of Wasm plugins into CRI-O, and exploring FreeBSD support. These initiatives aim to expand CRI-O's capabilities and address the needs of complex containerized environments.

Insights based on numbers:
- **Technical Enhancements:** The continuous introduction of new features and support for additional architectures and security mechanisms illustrates CRI-O's commitment to meeting the diverse needs of Kubernetes environments.

<iframe width="720" height="720" src="https://www.youtube.com/embed/q8AVAwdCqYk?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Create Cloud Native Agents and Extensions for LLMs - Xiaowei Hu, Second State" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 14. Create Cloud Native Agents and Extensions for LLMs - Xiaowei Hu, Second State

Xiaowei Hu's session focuses on leveraging WebAssembly (Wasm) to create efficient, cloud-native agents and extensions for Large Language Models (LLMs), with an emphasis on overcoming the challenges posed by traditional deployment methods. Here are the detailed insights:

- **Challenges with Python and Native Applications:**
  - **Python's Heavyweight Nature:** Python, commonly used for AI and LLM tasks, presents issues due to its large, complex dependencies. For instance, the Docker image for Python can be as large as the LLM itself, leading to inefficiency.
  - **Portability Issues with Native Applications:** While native applications in languages like Rust or C offer size advantages over Python, they lack portability. Recompiling applications for different environments (e.g., macOS vs. NVIDIA GPU) is necessary, a limitation in cloud-native settings where Kubernetes predominantly operates on binary artifacts.

- **Leveraging WebAssembly for Cloud-Native Development:**
  - **WebAssembly as a Solution:** The session introduces WebAssembly (Wasm) and the WebAssembly System Interface (WASI) as solutions to the portability and efficiency challenges. Wasm provides an abstraction layer between applications and underlying hardware, allowing for "write once, run anywhere" capabilities across different computing environments.
  - **WASI for System Functions:** WASI extends WebAssembly's capabilities to non-browser environments, enabling access to system functions like networking and file systems. This is crucial for AI and LLM workloads, which often require intensive computational resources.

- **Integration with Large Language Models:**
  - **Creating Lightweight Inference Applications:** By abstracting GPU drivers and inference frameworks through Wasm, developers can create applications that are not only portable but also significantly smaller in size compared to traditional Python-based solutions. This approach reduces the deployment size from gigabytes to megabytes, enhancing deployment efficiency.
  - **Supporting a Range of AI and LLM Workloads:** The session demonstrates how WebAssembly and WASI can support a diverse range of AI models and frameworks, including PyTorch, TensorFlow, and large language models like GPT-3. This versatility is showcased through the deployment of LLM applications on various hardware platforms, highlighting the flexibility and efficiency of the Wasm approach.

- **Cloud-Native Deployments and Kubernetes Integration:**
  - **Kubernetes Integration:** A key part of the discussion is the integration of Wasm applications with Kubernetes, allowing for the deployment of Wasm-based AI and LLM workloads in a cloud-native environment. This integration enables the utilization of Kubernetes' orchestration capabilities for managing Wasm applications, ensuring efficient resource utilization and scalability across cloud environments.

- **Demonstrations and Use Cases:**
  - **Demo Applications:** The presentation includes demonstrations of deploying LLM applications using Wasm, showcasing the process of compiling applications to Wasm bytecode and deploying them across different devices. These demos underline the practical benefits of using Wasm for cloud-native AI and LLM deployments, including portability, efficiency, and integration with Kubernetes.

- **Future Directions:**
  - **Expanding Wasm's Ecosystem:** The session hints at future developments in expanding the ecosystem of tools and frameworks supporting Wasm for AI and LLM applications. This includes enhancing the support for different AI models, optimizing performance for various hardware platforms, and further integrating with cloud-native technologies.

Insights based on numbers:
- **Reduction in Application Size:** The transformation from gigabyte-sized Docker images to megabyte-sized Wasm applications represents a significant leap in deployment efficiency, crucial for cloud-native environments.

<iframe width="720" height="720" src="https://www.youtube.com/embed/rJ6vebxS0aI?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Tackling Configuration Management at Scale with Flux, CUE and OCI at... Alec Hothan &amp; Stefan Prodan" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 15.Tackling Configuration Management at Scale with Flux, CUE and OCI at Cisco

The presentation by Alec Hothan and Stefan Prodan addresses complex configuration management for Kubernetes at scale, leveraging Flux, CUE, and OCI artifacts. Their insights cover the deployment challenges at Cisco with hundreds of clusters, integrating diverse workloads, and strategies for effective GitOps practices. Below are the highlighted points:

- **Challenges and Scale:**
  - **Deployment Scope:** Cisco faced the challenge of deploying a wide variety of workloads across hundreds of clusters worldwide, including on-premises and cloud environments. The scale required a robust configuration management solution to handle variations across different data centers and cluster types.

- **Flux for GitOps:**
  - **Adopting Flux:** Flux was chosen for its GitOps capabilities, allowing teams to manage Kubernetes resources through Git repositories. This approach facilitated collaboration among over 200 team members, including developers, testers, and operations teams.
  - **Multi-level Git Repositories:** To manage configurations for different environments, a two-level Git repository strategy was employed. This setup separated application source code and deployment configurations, enabling more controlled updates and permissions management.

- **CUE for Configuration Validation:**
  - **Employing CUE:** CUE was introduced to validate configurations and ensure consistency across deployments. Its ability to import Kubernetes API specs and perform client-side validation offered a way to catch errors early in the development process, enhancing the reliability of deployments.

- **OCI Artifacts for Configuration Storage:**
  - **Utilizing OCI Artifacts:** Transitioning from Git to OCI artifacts for storing Kubernetes configurations was proposed as a solution to remove Git as a production dependency. This approach leverages container registries for storing and retrieving configurations, benefiting from their inherent scalability and availability.

- **Timony for Template Generation:**
  - **Introduction of Timony:** Stefan Prodan discussed Timony, a tool designed to generate Kubernetes configurations using CUE. Timony aims to simplify template creation by providing a type-safe, modular approach to defining Kubernetes resources, reducing the complexity associated with managing large-scale deployments.

- **Best Practices and Innovations:**
  - **Blueprints for Deployment Instructions:** Deployments are structured around blueprints, which define how workloads should be deployed across various clusters. These blueprints facilitate the reuse of configurations and streamline the deployment process.
  - **Variable Substitution and Config Maps:** Flux's variable substitution feature was highlighted as a flexible way to customize deployments per cluster, allowing for granular control over deployment parameters.

- **Future Directions:**
  - **Timony Development:** Future work includes stabilizing Timony's API, promoting its Flux distribution for edge deployments, and potentially developing a Timony controller for Kubernetes, aiming to further streamline the deployment process.

- **Closing Thoughts:**
  - The presentation underscored the importance of efficient configuration management in large-scale Kubernetes environments. Through the integration of Flux, CUE, OCI artifacts, and the innovative use of Timony, the speakers shared valuable strategies for managing complexity and improving deployment reliability.

<iframe width="720" height="720" src="https://www.youtube.com/embed/tClsqnZMN6I?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="eBPF’s Abilities and Limitations: The Truth - Liz Rice &amp; John Fastabend, Isovalent" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 16. eBPF’s Abilities and Limitations: The Truth - Liz Rice & John Fastabend, Isovalent

Liz Rice and John Fastabend's presentation delves into the capabilities and perceived limitations of eBPF (Extended Berkeley Packet Filter), a revolutionary technology that enhances the flexibility and security of the Linux kernel without altering its code. The session aims to demystify eBPF's potential and limitations through technical insights and demonstrations, including an eBPF-based implementation of Conway's Game of Life. Here are the key takeaways:

- **eBPF Overview:**
  - **Functionality:** eBPF allows for the execution of custom programs within the kernel, offering the ability to modify kernel behavior dynamically. This capability is crucial for tasks involving hardware access, network communication, and memory management.

- **Misconceptions Addressed:**
  - **Complex Processing:** Contrary to beliefs that eBPF cannot handle complex layer 7 processing, the speakers argue that eBPF's design and continuous evolution enable it to manage complex tasks effectively.
  - **Turing Completeness:** The discussion touched on Turing completeness, explaining that while eBPF is not Turing complete due to its design to ensure safety and prevent indefinite execution, it still can process complex and varied tasks within its operational constraints.

- **Verifier and Limitations:**
  - **Safety Mechanisms:** The eBPF verifier plays a crucial role in ensuring program safety by preventing unauthorized memory access and ensuring that eBPF programs terminate or release the CPU to avoid monopolizing system resources.
  - **Instruction Limits:** Initially capped at 4,096 instructions, eBPF programs can now contain up to 1 million instructions, vastly expanding their complexity and potential applications.

- **Looping and Function Calls:**
  - **Enhanced Capabilities:** Recent kernel versions have introduced support for bounded loops and function calls within eBPF programs, allowing for more sophisticated and efficient program structures.

- **Memory Allocation and Execution:**
  - eBPF's design includes mechanisms for allocating and managing memory efficiently, supporting large-scale and complex operations within the kernel space.

- **Demonstration - Game of Life:**
  - **Practical Example:** A live demonstration of Conway's Game of Life running as an eBPF program showcased eBPF's ability to execute complex algorithms. This example highlighted eBPF's growth beyond its initial networking-focused applications to more generalized computing tasks.

- **Future of eBPF:**
  - **Continuous Evolution:** eBPF is under active development, with the community working towards enhancing its functionality, usability, and scope. The speakers emphasized the importance of community engagement and contributions to driving eBPF forward.

- **eBPF's Impact on Infrastructure Tools:**
  - **Real-world Applications:** Projects like Cilium and Tetragon utilize eBPF for networking, security, and observability, underscoring eBPF's utility in creating powerful infrastructure tools.

In conclusion, Liz Rice and John Fastabend's session challenges misconceptions about eBPF's limitations, illustrating its potential through technical explanation and a creative demonstration. As eBPF continues to evolve, its applications in cloud-native technologies are expected to expand, further integrating eBPF into the fabric of modern computing environments.

<iframe width="720" height="720" src="https://www.youtube.com/embed/vLc-nCwojIM?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Squeeze Your K8s: How We Adopt Time-Series Forecasting Models in FinOps... Irvin Lim &amp; Nicholas Kwan" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 17.Squeeze Your K8s: How We Adopt Time-Series Forecasting Models in FinOps Practices by Irvin Lim &amp; Nicholas Kwan

Irvin Lim and Nicholas Kwan's presentation delves into leveraging time-series forecasting to enhance financial operations (FinOps) efficiency in Kubernetes (K8s) environments. They discuss their journey from initial node-level optimizations to comprehensive fleet management, aiming to reduce costs while supporting an ever-growing container workload. Here are the key insights:

- **Challenges at Scale:** Managing over 100,000 pods across thousands of nodes worldwide presents significant cost implications. The key challenge is optimizing resource use to support this scale without incurring prohibitive expenses.

- **Resource Utilization Patterns:** Observation revealed common cases of resource wastage, particularly during off-peak hours and campaign events. These patterns indicated opportunities for resource optimization.

- **Adopting Time-Series Forecasting:** The approach utilizes time-series forecasting to predict resource utilization, enabling more efficient resource allocation and scaling. Short-term forecasting smoothes out immediate fluctuations to minimize unnecessary evictions, while long-term forecasting predicts usage patterns to make informed scheduling decisions.

- **Implementing Extended Resources:** By monitoring unused node resources, they reclaimed and advertised these through extended resources, allowing for additional workload placements beyond allocated capacities.

- **Batch Services:** They introduced a category for batch services that could utilize reclaimed resources, adjusting CPU weights and utilizing Linux kernel features to ensure online services retain priority.

- **Forecasting Techniques:** Utilizing exponentially weighted moving averages (EWMA) for short-term forecasts and Fourier transforms for long-term forecasts, they smoothed and predicted resource utilization patterns. This allowed for more precise scaling and resource allocation strategies.

- **Architecture for Forecasting Implementation:** The architecture involved collecting metrics via Prometheus, processing data through Spark pipelines, and integrating forecasts into Kubernetes scheduling decisions. This system enables more effective resource utilization across their Kubernetes fleet.

- **Challenges and Considerations:** The approach required careful management to avoid excessive evictions or resource contention. Additionally, forecasting models needed to balance complexity and accuracy against performance and computational costs.

- **Future Directions and Improvements:** Exploring more sophisticated forecasting models, including machine learning and deep learning approaches, could offer improved accuracy and responsiveness to trends and anomalies. However, these models present their own set of challenges, such as training costs and the need for fine-tuning.

- **Impact and Results:** The adoption of time-series forecasting in FinOps has led to more efficient resource use, reduced costs, and supported the scaling of Shopee's Kubernetes infrastructure. The techniques discussed offer valuable insights into managing large-scale Kubernetes environments more effectively.

<iframe width="720" height="720" src="https://www.youtube.com/embed/46dGFsIxCLA?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="KubeDDR! a Dance of Predictive Scoring with MLOps, Step by Step - Leigh Capili &amp; Annie Talvasto" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 18. KubeDDR! A Dance of Predictive Scoring with MLOps, Step by Step - Leigh Capili & Annie Talvasto

Leigh Capili and Annie Talvasto's presentation on "KubeDDR! A Dance of Predictive Scoring with MLOps, Step by Step" offers an intriguing blend of machine learning operations (MLOps), Kubernetes (K8s), and the interactive game Dance Dance Revolution (DDR). Through a playful yet informative exploration, they demonstrate how predictive scoring models can be applied within the gaming and sports context, specifically focusing on DDR. Here are the detailed insights:

- **Combining Esports and Physical Activity:** DDR represents a unique intersection of esports and physical activity. By integrating computer vision and predictive scoring, the speakers showcase how technological advancements can enhance player interaction and game analysis.

- **Computer Vision for Game Interaction:** Using computer vision, the speakers describe a method for detecting when a DDR pad is occupied, highlighting the potential for real-time game interaction and scoring.

- **Predictive Scoring with OCR:** Optical Character Recognition (OCR) technology is leveraged to analyze DDR gameplay, focusing on detecting scores from the game display. This approach exemplifies how predictive scoring can be employed to dynamically evaluate player performance.

- **MLOps for Deploying Models:** The challenges of deploying machine learning models into production environments are addressed. MLOps practices, including containerization with Docker and orchestration with Kubernetes, are discussed as solutions to streamline the deployment process.

- **Practical Demonstration:** A live demonstration, involving DDR gameplay, computer vision, and OCR, vividly illustrates the application of the discussed technologies. Despite background noise and visual interference challenges, the demo provides a real-world example of predictive scoring in action.

- **The Path to Production:** Highlighting the hurdles of bringing machine learning models to production, the presentation acknowledges the complexity of MLOps and the necessity of overcoming technical challenges to achieve operational efficiency.

- **Resources and Further Reading:** Attendees are directed to additional resources for diving deeper into computer vision, MLOps, and the specifics of implementing similar projects. These resources serve as a springboard for further exploration and development in the field.

- **Future Directions:** The presentation hints at the broader applicability of the discussed technologies beyond gaming, suggesting potential uses in sports analytics, training, and even predictive modeling for event outcomes.

<iframe width="720" height="720" src="https://www.youtube.com/embed/4SqDRokC7ac?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Fluent Bit v3: Unified Layer for Logs, Metrics and Traces - Eduardo Silva, Calyptia" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 19. Fluent Bit v3: Unified Layer for Logs, Metrics and Traces - Eduardo Silva, Calyptia

Eduardo Silva’s presentation on Fluent Bit version 3 dives deep into the latest enhancements and features of Fluent Bit, a CNCF graduated project renowned for its efficiency in processing logs, metrics, and traces. Here's a concise overview of the key points discussed:

- **Background and Evolution:**
  - Fluent Bit has matured significantly since its inception, expanding its capabilities from logs to metrics and now traces. Originating from a need to manage telemetry data efficiently, Fluent Bit has evolved into a critical tool within the CNCF ecosystem, alongside Kubernetes and OpenTelemetry.

- **Adoption and Community Growth:**
  - The project’s success is highlighted by its wide adoption and active community contribution, underpinning its status as a trusted and sustainable solution for telemetry data management.

- **Unified Data Processing:**
  - Fluent Bit's architecture enables unified processing of logs, metrics, and traces, providing a cohesive solution for telemetry data. It abstracts data types to facilitate agnostic processing and flexible backend integrations.

- **Version 3 Enhancements:**
  - Key features introduced in Fluent Bit v3 include HTTP/2 support, a new serialization format for improved performance, and several powerful processors such as Content Modifier and SQL Processor, enhancing data manipulation capabilities.

- **Content Modifier Processor:**
  - This new processor supports a wide range of actions (e.g., insert, upsert, delete, rename) on logs and traces, demonstrating Fluent Bit’s flexibility in data handling.

- **Metrics Selector Processor:**
  - The Metrics Selector allows for the inclusion or exclusion of specific metrics by name, optimizing the telemetry data sent to backends.

- **SQL Processor:**
  - A significant addition, the SQL Processor, offers SQL-like querying capabilities for logs, enabling sophisticated data selection and transformation without custom scripting.

- **OpenTelemetry Integration:**
  - Fluent Bit ensures compatibility with OpenTelemetry, supporting both ingestion and export of telemetry data in OpenTelemetry formats, solidifying its role in modern observability stacks.

- **Performance and Scalability:**
  - The introduction of multi-threading and coroutine support in recent versions addresses scalability challenges, enabling efficient data processing and transmission even in high-volume environments.

- **Future Directions:**
  - Continuous innovation, with plans for expanded metrics capabilities, deeper integration with cloud-native ecosystems, and enhancements to the Fluent ecosystem, promise to further elevate Fluent Bit's utility.

- **Community-Driven Development:**
  - Silva emphasizes the importance of community feedback and contributions in shaping Fluent Bit's roadmap, reflecting the project’s commitment to addressing real-world challenges in observability.

<iframe width="720" height="720" src="https://www.youtube.com/embed/5scIQkclPfk?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Kubernetes Security Blind Spot: Misconfigured System Pods - Shaul Ben Hai, Palo Alto Networks" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 20.Kubernetes Security Blind Spot: Misconfigured System Pods - Shaul Ben Hai, Palo Alto Networks

Shaul Ben Hai from Palo Alto Networks addresses a significant vulnerability in Kubernetes: the security blind spot created by misconfigured system pods. This presentation delves into the nuances of container escape and second-stage attacks in Kubernetes, emphasizing the critical role system pods play in both the functionality and security of Kubernetes clusters.

**Container Escape and Second-Stage Attacks:**
- Containers, despite their packaging and deployment benefits, are not foolproof security boundaries due to shared kernels. Container escapes are likely to continue, highlighting the importance of understanding their impact on Kubernetes, where they can compromise nodes or even entire clusters.

**System Pods - Privilege vs. Risk:**
- System pods, essential for cluster operation, pose a unique security challenge due to their elevated privileges. These pods execute critical tasks and maintain cluster functionality but their elevated access makes them a high-value target for attackers.

**Real-World Misconfigurations and Vulnerabilities:**
- The talk presents a case study combining two default misconfigurations in Google Kubernetes Engine (GKE), demonstrating how these can be exploited to escalate privileges to cluster admin level.

**Security Recommendations and Best Practices:**
- Key recommendations include minimizing pod privileges, limiting network access, and proactive monitoring to mitigate the inherent risks associated with system pods.

**Insights based on numbers:**
- The analysis emphasizes that while containers offer deployment advantages, their security implications, especially in the context of Kubernetes, cannot be overlooked. The dual nature of system pods as both essential and potentially vulnerable highlights the complex security landscape of Kubernetes clusters.

<iframe width="720" height="720" src="https://www.youtube.com/embed/8Zwftqf8g8w?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Keeping Kubernetes Safe: The Lowdown on Locked Namespaces - Marco De Benedictis, ControlPlane" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 21.Keeping Kubernetes Safe: The Lowdown on Locked Namespaces - Marco De Benedictis, ControlPlane

Educational summary of [Keeping Kubernetes Safe: The Lowdown on Locked Namespaces - Marco De Benedictis, ControlPlane](https://youtu.be/8Zwftqf8g8w) by [Video Summarizer](https://chat.openai.com/g/g-GvcYCKPIH-video-summarizer-ai):

Marco De Benedictis from ControlPlane discusses the critical role of namespaces in Kubernetes security, highlighting how misconfigured namespaces can expose Kubernetes clusters to various security threats. This presentation not only identifies common misconfigurations and their implications but also offers practical mitigation strategies.

**Namespace Basics and Security Implications:**
- Namespaces are not inherently security features but play a crucial role in organizing resources and influencing the security posture of a Kubernetes cluster.
- Misconfigurations at the namespace level can significantly impact security, affecting everything from role-based access control (RBAC) to resource management and network policies.

**Role-Based Access Control (RBAC):**
- Namespaces are essential for enforcing authorization policies within a cluster, allowing for fine-grained access control to resources.

**Networking and Namespaces:**
- Several Kubernetes networking features rely on namespace configurations, including DNS resolution, cross-namespace communication, and network policies. Misconfigured namespaces can lead to unauthorized access and potential data exfiltration.

**Security Context and Pod Security Standards:**
- Pod security standards, which replace Pod Security Policies (PSPs), are defined at the namespace level. Misconfigurations can lead to lax security contexts, allowing for the execution of privileged operations.

**Resource Management:**
- Kubernetes features like resource quotas and limit ranges are namespace-bound and crucial for preventing resource exhaustion attacks by noisy neighbors or malicious actors.

**Mitigations and Best Practices:**
- Least privilege RBAC: Ensure access to namespace objects is minimized, and audit changes regularly.
- Use immutable labels: Apply immutable labels to prevent unauthorized changes by attackers.
- Policy engines: Implement policies using tools like Kyverno to enforce namespace naming conventions, restrict label modifications, and prevent the creation of namespaces with names mimicking top-level domains or system namespaces.

**Insights based on numbers:**
- The presentation underscores the importance of namespaces in Kubernetes security architecture, showing how they intersect with multiple security mechanisms. Despite not providing isolation, namespaces serve as a fundamental aspect of security feature configurations, underscoring the criticality of proper management and configuration to safeguard Kubernetes environments.

<iframe width="720" height="720" src="https://www.youtube.com/embed/9A1mU-EbXrE?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Precision Matters: Scheduling GPU Workloads on Kubernetes - Amit Kumar &amp; Gaurav Kumar, Uber" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 22.Precision Matters: Scheduling GPU Workloads on Kubernetes - Amit Kumar &amp; Gaurav Kumar, Uber

Amit Kumar and Gaurav Kumar from Uber discuss the complexities and solutions related to scheduling GPU workloads on Kubernetes. This session delves into the challenges faced by Uber’s Compute Platform team in efficiently utilizing GPU resources for AI/ML workloads.

**Challenges in GPU Workload Scheduling:**
- **Heterogeneous Clusters:** Ensuring that GPU resources are used exclusively for GPU workloads, preventing CPU workloads from occupying GPU nodes.
- **Multiple GPU SKUs:** Matching workloads with appropriate GPU types to ensure optimal performance and cost efficiency.
- **Resource Fragmentation:** Minimizing resource fragmentation to ensure that larger GPU workloads can be accommodated.

**Solutions and Implementations:**
- **Node Labeling:** Labeling nodes based on GPU presence and type to guide scheduling decisions.
- **Filter Plugins:** Developing custom Kubernetes scheduler plugins to prevent non-GPU workloads from being scheduled on GPU nodes and to ensure that workloads are matched with appropriate GPU SKUs.
- **Bin Packing Strategy:** Adjusting scheduling strategies to pack workloads more densely and reduce fragmentation.

**Benefits and Outcomes:**
- Enhanced **resource utilization** and **cost savings**, estimated at half a million dollars annually, by ensuring workloads are scheduled on appropriate GPU types.
- **Improved model accuracy** by matching workloads with the best-suited GPU SKUs.

**Common Pitfalls and Solutions:**
- **Device Plugin Conflicts:** Addressed by excluding system pods, including the NVIDIA device plugin, from custom filter plugin logic.
- **Over-requesting Resources:** Implementing admission controls to prevent scheduling pods that request more GPUs than available on any single node.
- **Privileged Containers:** Prohibiting privileged containers that can bypass resource limits and access all node GPUs.

**Future Directions:**
- **Fractional GPUs:** Investigating the use of NVIDIA Multi-Instance GPU (MIG) to allow workloads to share GPU resources more effectively.
- **Support for Multiple GPU Vendors:** Exploring the inclusion of GPUs from Intel and AMD to diversify the hardware and optimize cost and performance.

**Insights based on numbers:**
- Uber’s GPU utilization never exceeds 80% to ensure reliability and performance. The Compute Platform team continuously works on improving utilization rates for both CPU and GPU resources.

<iframe width="720" height="720" src="https://www.youtube.com/embed/ABbds5-zSqk?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Leveraging OCI 1.1 for Enhanced SBOM Integration and Vulnerability Scanning in Harbor" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 23.Leveraging OCI 1.1 for Enhanced SBOM Integration and Vulnerability Scanning in Harbor

This presentation focuses on the integration of the Open Container Initiative (OCI) 1.1 specification with Harbor, a Cloud Native Computing Foundation (CNCF) graduated project, to enhance the generation and management of Software Bills of Materials (SBOMs) and vulnerability scanning. The talk, delivered by experts in the field, outlines how Harbor leverages OCI 1.1 to attach SBOMs to container images, thereby improving vulnerability scanning capabilities and software supply chain security.

**Key Points Discussed:**

- **SBOM Importance:** SBOMs provide a comprehensive inventory of all components within a software artifact, enabling better security and compliance management. They are crucial for identifying vulnerabilities quickly and are encouraged by recent executive orders and security best practices.

- **OCI 1.1 Specification:** OCI 1.1 introduces the ability to link artifacts within OCI-compliant registries, allowing for SBOMs, signatures, and other security artifacts to be associated with container images. This significantly enhances the traceability and management of components across the software supply chain.

- **Harbor's Role:** Harbor, an open-source artifact registry, has adopted OCI 1.1 to allow users to attach SBOMs and other security documents to container images. Harbor’s plugable scanner framework also facilitates the integration with various vulnerability scanners, including Trivy, a comprehensive security scanner developed by Aqua Security.

- **Integration with Trivy:** The presentation showcases how Trivy is used within Harbor to generate and attach SBOMs to container images automatically. Trivy supports generating SBOMs in popular formats like SPDX and CycloneDX, which can be attached to images in Harbor as "accessories," enhancing the visibility of the software components and their vulnerabilities.

- **Automated SBOM Generation:** Harbor's configuration can be adjusted to automatically generate SBOMs upon image push, streamlining the process for developers and ensuring that all artifacts in Harbor have corresponding SBOMs for security analysis.

- **Vulnerability Scanning Enhancements:** With the integration of OCI 1.1 and SBOMs, Harbor can provide more efficient vulnerability scanning by analyzing the SBOM directly rather than the container image itself. This approach can lead to faster scans and more accurate detection of vulnerabilities applicable to the software components listed in the SBOM.

<iframe width="720" height="720" src="https://www.youtube.com/embed/B0Xm2kfU-yA?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="IAM Confused: Analyzing 8 Identity Breach Incidents - Maya Levine, Sysdig" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 24.IAM Confused: Analyzing 8 Identity Breach Incidents - Maya Levine, Sysdig

Maya Levine from Sysdig offers a comprehensive analysis of eight real-world identity breach incidents, shedding light on the crucial importance of robust identity and access management (IAM) in cloud security. The presentation underscores how IAM failures are a common thread in many security breaches, illustrating through real incidents the tactics used by attackers and providing actionable insights to fortify defenses.

**Key Insights from Identity Breach Incidents:**

- **Widespread IAM Confusion:** Levine emphasizes that confusion around IAM is understandable due to its complexity and rapid evolution. IAM is likened to the cloud's perimeter, with mismanagement of permissions, secrets, and identities being exploited in many breaches.

- **The Over-Permission Problem:** Research indicates that a staggering 98% of granted permissions are unused, presenting a significant attack surface. The talk stresses the necessity of adhering to the principle of least privilege and tailoring permissions closely to actual needs.

- **Human and Machine Identity Challenges:** Mistakes in IAM can stem from unclear ownership between DevOps and security teams, leading to vulnerabilities. Levine points out that attackers are adept at secret harvesting and can exploit even seemingly minor oversights, like case sensitivity in IAM policies.

- **Real-World Breach Analysis:** The presentation meticulously dissects several breach incidents, including:
    - A Kubernetes cluster breach where Jupiter notebook containers were exploited.
    - Attackers leveraging IAM misconfigurations and default roles to escalate privileges.
    - Social engineering attacks manipulating MFA and phishing to gain unauthorized access.
    - Hardcoded credentials in scripts providing attackers with a "golden key" to extensive privileges.
    - Misconfigured Kubernetes API servers allowing unauthorized access and persistence establishment.
    - The use of stolen VPN credentials to infiltrate and exfiltrate sensitive information.

**Strategies for Enhancing IAM Security:**

- **Strict Permission Management:** Implement a least-privilege model and regularly audit permissions to ensure they align with actual usage.

- **Clear Ownership and Accountability:** Define and communicate responsibilities for IAM posture between DevOps, IT, and security teams to prevent gaps and oversights.

- **Secrets Management:** Employ a centralized secrets management system to prevent credentials from being hardcoded or stored insecurely.

- **Education and Training:** Increase awareness and training for employees to recognize and resist social engineering attempts.

- **Advanced MFA Strategies:** Beyond enabling MFA, organizations should restrict MFA registrations to trusted locations and devices, limit the number of devices that can receive MFA requests, and alert on login attempts from unusual locations.

- **Invest in IAM Tools and Processes:** Utilize Cloud Infrastructure Entitlement Management (CIEM) tools to detect excessive permissions and improve identity hygiene. Ensure network segmentation to hinder lateral movement and deploy Cloud Detection and Response (CDR) for real-time threat detection.

<iframe width="720" height="720" src="https://www.youtube.com/embed/Cr2Kwht3lqY?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="You Shall Not Pass! Unless You Are GUAC Verified - Parth Patel, Kusari &amp; Dejan Bosanac, Red Hat" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 25.You Shall Not Pass! Unless You Are GUAC Verified - Parth Patel, Kusari &amp; Dejan Bosanac, Red Hat

Parth Patel of Kusari and Dejan Bosanac of Red Hat delve into the criticality of software supply chain security, particularly focusing on the GUAC (Graph for Understanding Artifact Composition) framework. This presentation showcases how GUAC, alongside Kusari and other open-source projects, enhances the security and trustworthiness of software artifacts through comprehensive verification processes.

**Key Highlights:**

- **Software Supply Chain Vulnerabilities:** The talk begins with an overview of the diverse threats plaguing the software supply chain, ranging from source code to build and packaging vulnerabilities, emphasizing the necessity of vigilant management across all stages.

- **Introduction to GUAC:** GUAC serves as a central repository that aggregates data from various sources, including SBOMs (Software Bill of Materials), vulnerability databases, and build attestations. It represents these relationships within a graph database, facilitating a more nuanced understanding of artifact composition and potential security risks.

- **Vulnerability Exploitability Exchange (VEX):** A crucial part of GUAC's utility lies in its ability to filter out the noise of omnipresent vulnerabilities by leveraging VEX files. VEX files allow maintainers to indicate whether specific vulnerabilities affect their project, thus enabling targeted and efficient security measures.

- **Demonstration of GUAC in Action:** The presentation includes a live demo where GUAC, integrated with Kubernetes through Open Policy Agent (OPA) and Gatekeeper, enforces deployment policies based on the security posture of container images. It illustrates GUAC's ability to reject or accept deployments based on the presence of SBOMs, build attestations, and identified vulnerabilities.

- **Policy Enforcement and Automation:** By incorporating policy checks directly into the Kubernetes deployment process, GUAC empowers organizations to automate security decisions. It supports a proactive approach to software security, ensuring that only verified artifacts are deployed.

- **Collaboration and Open Source Contribution:** Patel and Bosanac stress the importance of community involvement in the ongoing development and refinement of GUAC and related projects. They invite contributions to address the numerous challenges in supply chain security and to help evolve GUAC's capabilities.

<iframe width="720" height="720" src="https://www.youtube.com/embed/H0Cdf--4uq8?list=PLj6h78yzYM2N8nw1YcqqKveySH6_0VnI0" title="Search at Shopify: Highly Available Platform for Data Resilience and Compliance - Leila Vayghan" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 26.Search at Shopify: Highly Available Platform for Data Resilience and Compliance - Leila Vayghan

Leila Vayghan, an infrastructure engineer at Shopify, provides a comprehensive overview of Shopify's search platform, detailing the architecture, technologies, and strategies employed to ensure high availability, scalability, and global access. The presentation focuses on how Shopify hosts its search infrastructure on Kubernetes, managing data resilience and compliance effectively.

**Shopify's Search Infrastructure Overview:**
- Shopify, a major cloud-based commerce platform, handles immense volumes of data and requests, especially during peak events like Black Friday Cyber Monday (BFCM).
- The search functionality is crucial for both merchants and buyers, utilizing Elasticsearch as a secondary data store for fast search capabilities, full-text search, and data aggregations.

**Technological Foundation:**
- **Elasticsearch:** A distributed search and analytics engine known for its scalability and fault tolerance, essential for e-commerce functionalities.
- **Kafka:** An open-source distributed streaming platform used at Shopify for building real-time data pipelines and streaming applications, facilitating the movement of data from SQL databases to Elasticsearch.

**Shopify's Data Pipeline:**
- The data pipeline, consisting of Kafka topics and consumers, processes records from Shopify's SQL databases, pushing updates to Elasticsearch in real time.
- Shopify maintains a "Search Platform" team, dedicated to developing and maintaining the infrastructure that powers search functionalities across the platform.

**High Availability and Scalability:**
- The presentation underscores the importance of high availability and redundancy, with Elasticsearch providing built-in fault tolerance through shard replication across multiple nodes.
- Shopify's custom Kubernetes controller plays a pivotal role in managing Elasticsearch clusters, ensuring data redundancy and handling scalability needs, including automatic storage scaling.

**Globalization and Data Locality:**
- Post-COVID-19, Shopify expanded its operations globally to reduce latency and comply with data jurisdiction requirements, necessitating the search infrastructure to be closer to clients worldwide.
- Shopify manages over 100 distinct Elasticsearch clusters across the globe, handling more than 3 petabytes of data and ensuring that search functionalities are optimized for merchants and buyers in various regions.

**Key Takeaways:**
- **Custom Kubernetes Controller:** Shopify developed a custom controller to manage Elasticsearch clusters on Kubernetes, allowing for flexible, scalable, and highly available search services.
- **Data Pipeline Efficiency:** Through the integration of Kafka for real-time data processing and Elasticsearch for search functionalities, Shopify ensures a seamless and efficient data pipeline.
- **Global Reach and Compliance:** The search platform's expansion and adaptability to various regions underline Shopify's commitment to providing fast, reliable, and compliant search experiences to its global user base.



